### 并发版爬虫 发现问题

#### 1、限流问题
* 单个节点能够承受的流量有限
* 解决：将Worker放到不同的节点
#### 2、去重问题
* 单节点能承受的去重数据量有限
* 无法保存之前去重结果
* 基于Key-Value Store (如Redis)进行分布式去重
* > 解决：将“去重”拉出去做成一个服务，并让Worker调去重，防止卡住。
  > 
#### 3、存储问题
* 存储部分的结构，技术栈和爬虫部分区别很大
* 进一步优化需要特殊的ElasticSearch技术背景
* 固有分布式（人的分布式）
* > 解决：将ItemSaver做成一个服务